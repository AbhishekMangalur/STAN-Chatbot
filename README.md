# ğŸ’¬ STAN Chatbot - Intelligent Conversational Agent

Welcome to the STAN Chatbot project! This AI-powered assistant demonstrates human-like interaction, memory, tone awareness, and local+cloud integration. Designed as part of the **STAN Internship Challenge**, this chatbot can be embedded into user-generated content (UGC) platforms and social apps.

---

## ğŸ”¥ Features Implemented

| Feature                      | Description                                                            |
| ---------------------------- | ---------------------------------------------------------------------- |
| ğŸ’¡ Local + Cloud LLM Support | Runs locally with Ollama (Mistral/LLaMA3) or via Gemini Flash 2.5 API  |
| ğŸ§  Long-Term Memory Recall   | Remembers user identity and preferences with TinyDB                    |
| ğŸ—£ï¸ Tone Adaptation          | Detects tone (happy, sad, angry) and adapts response style dynamically |
| ğŸ‘¥ Personalized Interaction  | Builds context with each conversation to personalize replies           |
| ğŸ“„ PDF Summarization         | Upload a PDF and receive a summary via chat                            |
| ğŸ“¬ Chat UI with Streamlit    | Modern UI with Enter-to-send and chat bubbles                          |
| ğŸ“ Modular FastAPI Backend   | Clean, scalable architecture with memory and chatbot separation        |
| ğŸ” Secure Config Management  | .env and config.py for environment settings                            |

---

## ğŸ—ï¸ Project Structure

```
stan-chatbot/
â”œâ”€â”€ main.py              # FastAPI entry point
â”œâ”€â”€ chatbot.py           # Chat logic (Gemini API or local Ollama)
â”œâ”€â”€ memory.py            # TinyDB-based memory handling
â”œâ”€â”€ utils.py             # Tone detection + identity extraction
â”œâ”€â”€ streamlit_chat.py    # Frontend UI via Streamlit
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ .env                 # API keys and secrets (excluded via .gitignore)
â”œâ”€â”€ config.py            # Loads environment variables
â””â”€â”€ memory.json          # Persistent memory store
```

---

## ğŸš€ Deployment

This app can be deployed via:

* âœ… Localhost (`uvicorn main:app` + `streamlit run streamlit_chat.py`)
* â˜ï¸ Render (FastAPI backend hosted)
* â›… HuggingFace Spaces (Optional for UI)

---

## ğŸ“¥ Installation (Local)

```bash
git clone https://github.com/your-username/stan-chatbot.git
cd stan-chatbot
python -m venv venv
source venv/bin/activate  # or venv/Scripts/activate
pip install -r requirements.txt

# Run Backend
uvicorn main:app --reload

# Run Frontend
streamlit run streamlit_chat.py
```

---

## âš™ï¸ Gemini API Setup

1. Get API key from [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
2. Add to `.env`:

```
GEMINI_API_KEY=your-key-here
```

---

## ğŸ§ª Test Cases (Validated)

* âœ… Long-Term Memory: Remembers name, likes, facts
* âœ… Tone Matching: Detects sadness, humor, emotion
* âœ… Personalization: Remembers interests, adjusts style
* âœ… Naturalness: Varies replies, no template loops
* âœ… Identity Consistency: Doesnâ€™t break character
* âœ… Hallucination Safety: No false claims or memories

---

## ğŸ“¸ Screenshots

![Diagram](/images/Homepage.png)

![Diagram](/images/reply.png)

&#x20;

---

## ğŸ“Œ Architecture Overview

* User Input â†’ Streamlit UI â†’ FastAPI Backend
* Gemini API or Ollama â†’ Response â†’ Memory Update
* PDF Summarization â†’ Context-aware Summary

---

## ğŸ‘¨â€ğŸ’» Contributors

* Abhishek M (Developer)

---

## ğŸ“„ License

This project is licensed for educational use as part of the STAN Internship Challenge.
