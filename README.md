ğŸ’¬ STAN Chatbot â€“ Human-Like Conversational Agent
STAN is a personalized, context-aware chatbot powered by a local LLM (Mistral or LLaMA3 via Ollama). Built with FastAPI and Streamlit, STAN adapts to user emotions, remembers personal information, and performs intelligent tasks like document summarization â€” all running locally without API costs.

ğŸš€ Features
Feature	Description
ğŸ§  Human-Like Responses	Generates natural, varied replies (not robotic or templated)
ğŸ—£ï¸ Adaptive Tone Matching	Detects emotional tone & adjusts style (happy, angry, neutral, etc.)
ğŸ“¦ Long-Term Memory	Remembers user name, location, interests across sessions (TinyDB)
ğŸ”’ Secure API-Free Setup	Runs Mistral/LLaMA3 locally via Ollama â€” no billing, no tokens
ğŸ§¾ PDF Summarization	Upload a PDF and STAN will summarize it intelligently
ğŸ§  Identity Recall	Bot remembers facts like â€œI live in Delhiâ€ or â€œMy favorite color is blueâ€
ğŸ› Modular Architecture	Built using FastAPI (backend) and Streamlit (frontend)
ğŸ“¤ Enter-to-Send UI	Press Enter to send message (Shift+Enter for newline)

ğŸ“‚ Project Structure

ğŸ“ STAN/
â”œâ”€â”€ app.py                # FastAPI backend (POST /chat)
â”œâ”€â”€ chatbot.py            # Core logic for tone, model, and memory
â”œâ”€â”€ memory.py             # Persistent memory using TinyDB
â”œâ”€â”€ utils.py              # Tone detection and identity handling
â”œâ”€â”€ config.py             # Loads environment variables
â”œâ”€â”€ streamlit_chat.py     # Streamlit-based UI
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ memory.json           # Chat memory storage
â”œâ”€â”€ .env                  # For any keys (though not needed with Ollama)
â””â”€â”€ README.md             # You're here!

ğŸ–¥ï¸ Installation

Clone this repo:
git clone https://github.com/yourusername/STAN-chatbot.git

cd STAN-chatbot

Create a virtual environment:
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows

Install dependencies:
pip install -r requirements.txt

Install Ollama and a model:
Install Ollama â†’ https://ollama.com/download

Then pull a model:
ollama run mistral   # or ollama run llama3

â–¶ï¸ Running the App
In one terminal, start the FastAPI backend:
uvicorn main:app --reload

In another terminal, start the frontend:
streamlit run streamlit_chat.py

Then visit http://localhost:8501 in your browser.

âœ… Test Case Coverage
This project fulfills the full STAN Internship Challenge rubric:

âœ… Long-term memory recall

âœ… Personalized tone adaptation

âœ… Identity consistency under pressure

âœ… PDF summarization

âœ… No hallucinations or contradictions

âœ… Context reuse (e.g., â€œYou said you like animeâ€)

âœ… Natural conversation style (no templates)

ğŸ“„ Sample Prompts to Try
I live in Bangalore.

My name is Abhishek.

I'm feeling really down today.

What's the summary of this PDF? (Upload a file)

Do you remember where I live?

ğŸ“˜ License
This project is developed for educational purposes and is free to use under the MIT License.